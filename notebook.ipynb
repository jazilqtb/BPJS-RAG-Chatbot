{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4187629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jazil/miniconda3/envs/bpjs-rag-bot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is your name?\",\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545da713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: You are a helpful AI bot. Your name is jazi.\n",
      "Human: Hello, how are you doing?\n",
      "AI: I'm doing well, thanks!\n",
      "Human: Whats your name?\n"
     ]
    }
   ],
   "source": [
    "prompt_txt = template.format(name=\"jazi\", user_input=\"Whats your name?\")\n",
    "print(type(prompt_txt))\n",
    "print(prompt_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e741c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = MessagesPlaceholder(\"history\")\n",
    "# prompt.format_messages()  # raises KeyError\n",
    "\n",
    "prompt = MessagesPlaceholder(\"history\", optional=True)\n",
    "prompt.format_messages()  # returns empty list []\n",
    "\n",
    "prompt.format_messages(\n",
    "    history=[\n",
    "        (\"system\", \"You are an AI assistant.\"),\n",
    "        (\"human\", \"Hello!\"),\n",
    "    ]\n",
    ")\n",
    "# -> [\n",
    "#     SystemMessage(content=\"You are an AI assistant.\"),\n",
    "#     HumanMessage(content=\"Hello!\"),\n",
    "# ]\n",
    "\n",
    "# print(prompt.format_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721bf43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: what's 5 + 2\n",
      "AI: 5 + 2 is 7\n",
      "Human: now multiply that by 4\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "prompt.invoke(\n",
    "    {\n",
    "        \"history\": [(\"human\", \"what's 5 + 2\"), (\"ai\", \"5 + 2 is 7\")],\n",
    "        \"question\": \"now multiply that by 4\",\n",
    "    }\n",
    ")\n",
    "# -> ChatPromptValue(messages=[\n",
    "#     SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "#     HumanMessage(content=\"what's 5 + 2\"),\n",
    "#     AIMessage(content=\"5 + 2 is 7\"),\n",
    "#     HumanMessage(content=\"now multiply that by 4\"),\n",
    "# ])\n",
    "\n",
    "print(prompt.format(history=[(\"human\", \"what's 5 + 2\"), (\"ai\", \"5 + 2 is 7\")], question=\"now multiply that by 4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83fb6dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chain\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[1;32m     10\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mGENAI_MODEL,\n\u001b[1;32m     12\u001b[0m     api_key\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mGOOGLE_API_KEY,\n\u001b[1;32m     13\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "# CHAIN\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.base import Chain\n",
    "\n",
    "from src.core.config import settings\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=settings.GENAI_MODEL,\n",
    "    api_key=settings.GOOGLE_API_KEY,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"sistem\",\"Kamu adalah asisten AI\"),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0dd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpjs-rag-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
